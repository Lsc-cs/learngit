为了完成我的信息检索选修课大作业，写下了这个简单的小项目。

这里是一个python3 实现的简易的搜索引擎

我把它取名叫linyiSearcher

--------

所需要的python依赖包在requirements.txt中
可以使用 pip install -r requirements.txt 一次性安装全部

--------

一共分成3部分完成

1_spider.py 是一个爬虫， 爬取搜索引擎的语料库

2_clean_data_and_make_index  是对爬下来的数据 进行一些清晰工作，并且将数据存入数据库，建立索引
    
    这里使用了 sqlite数据库，为了方便数据和项目一同携带
    
3_searcher.py 简易的web后端， 实现了 

    1 在网页输入搜索关键字， 在后端接收到关键字
    
    2 对关键字进行分词
    
    3 在索引中查找和关键字有关的文档
    
    4 按照余弦相似度 对文档进行排序
    
    5 把相近的文档展示出来

--------

自己的知识储备和代码能力都捉襟见肘。

大神来看，还望海涵～欢迎大家批评指正共同学习

--------


1 爬虫：

    因为没有数据，只能写爬虫来做，　又只有自己的笔记本来跑，所以数据量也做不到非常大
    
    在这里　写了１程序　爬了百度贴吧 娱乐明星分类下面的所有1级页面帖子的标题 当做语料库
    
    爬取下来的数据存在了 ./data/database.csv 下
    
        数据有2列 分别是  title 和url
        
        
2 数据清洗 并 建立索引：

    database.db  是一个sqlite数据库文件
    
    首先将每个文档存到了数据库当中  
    
    数据库表为 page_info(id,keyword, title, url)
    
        id 自增主键 
        
        keyword: 存了该文档文字用jieba分词打散后的词汇列表（用空格隔开所有词语的字符串）
        
        title: 文档的文字内容 
        
        url: 该文档的网页链接
        
    然后 把每个文档 使用jieba分词工具， 打散成词语，把所有词语放到一个集合中（集合能去重）
    
        把所有词 存入数据库 建立索引  
        
        索引这样理解：
        
            关键词:  你好  包含关键词的文档： <1,2,6,8,9>
            
        表为 page_index(id, word, page_id)
        
            id: 自增 主键
            
            word: 当前关键词
            
            page_id: 包含该关键词的文档id 也就是page_info.id
            
            
    
3 实现检索：

    首先 使用了bottle框架，是一个非常轻巧的web后端框架，实现了一个简单的web后端
    
    前端页面使用了bootstrap 的css样式，，毕竟自己什么垃圾的一p
    
    检索的实现过程：
    
        1 后端拿到检索的关键词，用jieba分词 把拿到的语句打散成词汇 形成关键词keyword_list
        
        2 在建立的索引表page_index中，搜关keyword_list中出现的词汇的page_id
        
        3 在包含所有keyword的文档上 计算和keyword的余弦相似度，然后降序排列
        
        4 返回给前端显示搜索结果
        
        


